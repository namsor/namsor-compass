{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data Preparation\n",
    "\n",
    "To the pre-prepared COMPAS data we add predictions for name gender and origin made as made by NamSor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing necessary libraries... \n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# >>> Import Libraries\n",
    "\n",
    "print(\"Importing necessary libraries... \")\n",
    "\n",
    "import openapi_client #NamSor, see https://github.com/namsor/namsor-python-sdk2\n",
    "from openapi_client.rest import ApiException\n",
    "\n",
    "from aequitas.group import Group # Aequitas, see https://github.com/dssg/aequitas/blob/master/docs/source/examples/compas_demo.ipynb\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing COMPAS data set... \n",
      "Data set imported. It is has 7214 entries and looks like this:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>score</th>\n",
       "      <th>label_value</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>Greater than 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity_id   first         last  score  label_value              race   sex  \\\n",
       "0          1  miguel    hernandez    0.0            0             Other  Male   \n",
       "1          3   kevon        dixon    0.0            1  African-American  Male   \n",
       "2          4      ed        philo    0.0            1  African-American  Male   \n",
       "3          5   marcu        brown    1.0            0  African-American  Male   \n",
       "4          6  bouthy  pierrelouis    0.0            0             Other  Male   \n",
       "\n",
       "           age_cat  \n",
       "0  Greater than 45  \n",
       "1          25 - 45  \n",
       "2     Less than 25  \n",
       "3     Less than 25  \n",
       "4          25 - 45  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>> Import COMPAS data set\n",
    "\n",
    "print(\"Importing COMPAS data set... \")\n",
    "\n",
    "df = pd.read_csv(\"data/compas_for_namsor.csv\")\n",
    "\n",
    "print(\"Data set imported. It is has {} entries and looks like this:\".format(df.shape[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting private key... \n",
      "Got private key.\n"
     ]
    }
   ],
   "source": [
    "# >>> Preparing for API use\n",
    "\n",
    "# Get private API Key for NamSor API v2 (contained in txt file)\n",
    "print(\"Getting private key... \")\n",
    "\n",
    "key = ''\n",
    "\n",
    "try:\n",
    "    with open(\"key.txt\", \"r\") as file:\n",
    "        key = file.read()\n",
    "    if(len(key) < 0):\n",
    "        raise FileNotFoundError()\n",
    "except (FileNotFoundError):\n",
    "    print(\"Could not find private key. Please make sure you have an API key that you stored as key.txt in the root folder.\")\n",
    "\n",
    "print(\"Got private key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up NamSor API v2 connection settings...\n",
      "Connection set.\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up NamSor API v2 connection settings...\")\n",
    "\n",
    "# Configure API key authorization: api_key\n",
    "configuration = openapi_client.Configuration()\n",
    "configuration.api_key['X-API-KEY'] = key\n",
    "\n",
    "# create an instance of the personal API class\n",
    "pers_api_instance = openapi_client.PersonalApi(openapi_client.ApiClient(configuration))\n",
    "\n",
    "print(\"Connection set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting names dataframe...\n",
      "Names dataframe formatted. It looks like this: \n",
      "   entity_id   first         last\n",
      "0          1  miguel    hernandez\n",
      "1          3   kevon        dixon\n",
      "2          4      ed        philo\n",
      "3          5   marcu        brown\n",
      "4          6  bouthy  pierrelouis\n"
     ]
    }
   ],
   "source": [
    "# >>> Classifying names with NamSor API\n",
    "\n",
    "# Formatting a df of names and iso2 country codes, which is always 'us' in the COMPAS data set\n",
    "print('Formatting names dataframe...')\n",
    "\n",
    "names_df = df[['entity_id', 'first', 'last']]\n",
    "\n",
    "print('Names dataframe formatted. It looks like this: ')\n",
    "print(names_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_first_last_name_geo_in(row) :\n",
    "    ''' This function turns a tuple of values [id, first_name, last_name] into a to_first_last_name_geo_in object'''\n",
    "    # https://github.com/namsor/namsor-python-sdk2/blob/master/docs/FirstLastNameGeoIn.md\n",
    "    if(not row[0] or not row[1] or not row[2]):\n",
    "        print(\"Entered invalid data to be turned into to_first_last_name_geo_in\")\n",
    "        return\n",
    "    return openapi_client.FirstLastNameGeoIn(id=row[0], \n",
    "                                         first_name=row[1], \n",
    "                                         last_name=row[2], \n",
    "                                         country_iso2='us') # http://www.vas.com/Tnotes/Country%20Codes.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating list of name-batches...\n",
      "List of batches created.\n",
      "Will need to make 8 calls.\n"
     ]
    }
   ],
   "source": [
    "# Formatting a list of batches from the names df so names can be fed to the API batch-wise\n",
    "print('Creating list of name-batches...')\n",
    "\n",
    "names_stack = list() # this will be a list of name-batches generated from the df\n",
    "\n",
    "limit = len(names_df.index)\n",
    "start = 0\n",
    "end = -1\n",
    "batch_size = 1000 #1000 is the API limit given by NamSor\n",
    "\n",
    "while(end < limit):\n",
    "    start = end + 1\n",
    "    \n",
    "    try_end = end + batch_size\n",
    "    if(try_end <= limit):\n",
    "        end = try_end\n",
    "    else:\n",
    "        end = limit\n",
    "    \n",
    "    # each list item will fit openapi_client.BatchFirstLastNameGeoIn\n",
    "    current_df_batch = names_df[start:end]\n",
    "    \n",
    "    # https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas/55557758#55557758\n",
    "    list_first_last_name_geo_in = [to_first_last_name_geo_in(row) for row in current_df_batch[['entity_id', 'first', 'last']].to_numpy()]\n",
    "    names_stack.append(list_first_last_name_geo_in)\n",
    "    \n",
    "print('List of batches created.')\n",
    "\n",
    "print('Will need to make {} calls.'.format(len(names_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(list_first_last_name_geo_in):\n",
    "    return openapi_client.BatchFirstLastNameGeoIn(personal_names=list_first_last_name_geo_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender_batch(list_first_last_name_geo_in):\n",
    "    api_response = pers_api_instance.gender_geo_batch(batch_first_last_name_geo_in=batch_first_last_name_geo_in)# call api\n",
    "    return api_response.personal_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ethnicity_batch(list_first_last_name_geo_in):\n",
    "    # \"Output is W_NL (white, non latino), HL (hispano latino), A (asian, non latino), B_NL (black, non latino).\"\n",
    "    api_response = pers_api_instance.us_race_ethnicity_batch(batch_first_last_name_geo_in=batch_first_last_name_geo_in)# call api\n",
    "    return api_response.personal_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending batches to the API...\n",
      "All batches analyzed.\n",
      "[{'first_name': 'miguel',\n",
      " 'gender_scale': -0.9918105205926329,\n",
      " 'id': '1',\n",
      " 'last_name': 'hernandez',\n",
      " 'likely_gender': 'male',\n",
      " 'probability_calibrated': 0.9959052602963164,\n",
      " 'score': 40.48141974289901}, {'first_name': 'kevon',\n",
      " 'gender_scale': -0.9515955909827281,\n",
      " 'id': '3',\n",
      " 'last_name': 'dixon',\n",
      " 'likely_gender': 'male',\n",
      " 'probability_calibrated': 0.975797795491364,\n",
      " 'score': 23.930992858410622}, {'first_name': 'ed',\n",
      " 'gender_scale': -0.9609662625502784,\n",
      " 'id': '4',\n",
      " 'last_name': 'philo',\n",
      " 'likely_gender': 'male',\n",
      " 'probability_calibrated': 0.9804831312751392,\n",
      " 'score': 25.219659863806516}, {'first_name': 'marcu',\n",
      " 'gender_scale': -0.5838491405761623,\n",
      " 'id': '5',\n",
      " 'last_name': 'brown',\n",
      " 'likely_gender': 'male',\n",
      " 'probability_calibrated': 0.7919245702880812,\n",
      " 'score': 9.503246398640567}, {'first_name': 'bouthy',\n",
      " 'gender_scale': -0.28456843167061563,\n",
      " 'id': '6',\n",
      " 'last_name': 'pierrelouis',\n",
      " 'likely_gender': 'male',\n",
      " 'probability_calibrated': 0.6422842158353078,\n",
      " 'score': 3.6364421304413215}]\n",
      "[{'first_name': 'miguel',\n",
      " 'id': '1',\n",
      " 'last_name': 'hernandez',\n",
      " 'probability_alt_calibrated': 0.9850713313134039,\n",
      " 'probability_calibrated': 0.9755853512107264,\n",
      " 'race_ethnicities_top': ['HL', 'A', 'W_NL', 'B_NL'],\n",
      " 'race_ethnicity': 'HL',\n",
      " 'race_ethnicity_alt': 'A',\n",
      " 'score': 54.30918311767402}, {'first_name': 'kevon',\n",
      " 'id': '3',\n",
      " 'last_name': 'dixon',\n",
      " 'probability_alt_calibrated': 0.9659970528609386,\n",
      " 'probability_calibrated': 0.8577214178142619,\n",
      " 'race_ethnicities_top': ['B_NL', 'W_NL', 'A', 'HL'],\n",
      " 'race_ethnicity': 'B_NL',\n",
      " 'race_ethnicity_alt': 'W_NL',\n",
      " 'score': 17.60332492100772}, {'first_name': 'ed',\n",
      " 'id': '4',\n",
      " 'last_name': 'philo',\n",
      " 'probability_alt_calibrated': 0.7775179815107874,\n",
      " 'probability_calibrated': 0.6105848842272246,\n",
      " 'race_ethnicities_top': ['A', 'W_NL', 'B_NL', 'HL'],\n",
      " 'race_ethnicity': 'A',\n",
      " 'race_ethnicity_alt': 'W_NL',\n",
      " 'score': 5.810391702553957}, {'first_name': 'marcu',\n",
      " 'id': '5',\n",
      " 'last_name': 'brown',\n",
      " 'probability_alt_calibrated': 0.9100408858060703,\n",
      " 'probability_calibrated': 0.7629881877144955,\n",
      " 'race_ethnicities_top': ['B_NL', 'W_NL', 'A', 'HL'],\n",
      " 'race_ethnicity': 'B_NL',\n",
      " 'race_ethnicity_alt': 'W_NL',\n",
      " 'score': 11.526390244075507}, {'first_name': 'bouthy',\n",
      " 'id': '6',\n",
      " 'last_name': 'pierrelouis',\n",
      " 'probability_alt_calibrated': 0.9223489094711834,\n",
      " 'probability_calibrated': 0.8025664950934497,\n",
      " 'race_ethnicities_top': ['B_NL', 'A', 'W_NL', 'HL'],\n",
      " 'race_ethnicity': 'B_NL',\n",
      " 'race_ethnicity_alt': 'A',\n",
      " 'score': 13.496279554291483}]\n"
     ]
    }
   ],
   "source": [
    "# Sending in one batch at a time and saving the result answer by answer.\n",
    "\n",
    "print(\"Sending batches to the API...\")\n",
    "\n",
    "result_gender = []\n",
    "result_ethnicity = []\n",
    "current = 0\n",
    "limit = 2 #len(names_stack)\n",
    "\n",
    "while(len(result_gender) < limit): # I assume len(result_gender) == len(result_ethnicity)\n",
    "    batch_first_last_name_geo_in = get_batch(names_stack[current])\n",
    "    try:\n",
    "        result_gender.extend(predict_gender_batch(batch_first_last_name_geo_in))\n",
    "        result_ethnicity.extend(predict_ethnicity_batch(batch_first_last_name_geo_in))\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling PersonalApi: {}\".format(e))\n",
    "        if(len(result_gender) != (batch_size * current + len(names_stack[current])) or\n",
    "          len(result_ethnicity) != (batch_size * current + len(names_stack[current]))):\n",
    "            print(\"Some names got lost when the exception at stack {} occurred. Please try again.\".format(current))\n",
    "            break\n",
    "        if(len(result_gender) == (batch_size * current + len(names_stack[current]))):\n",
    "            print(\"No names got lost for gender predictions. Trying again with stack size {}...\".format(len(names_stack)))\n",
    "        if(len(result_ethnicity) == (batch_size * current + len(names_stack[current]))):\n",
    "            print(\"No names got lost for ethnicity predictions. Trying again with stack size {}...\".format(len(names_stack)))\n",
    "        current -= 1\n",
    "        continue\n",
    "    current += 1\n",
    "\n",
    "print(\"All batches analyzed.\")\n",
    "print(result_gender[:5])\n",
    "print(result_ethnicity[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling the results into the names dataframe...\n",
      "Dataframe completed with API results. Here are some results:            index   first         last  score  label_value              race  \\\n",
      "entity_id                                                                     \n",
      "1              0  miguel    hernandez    0.0            0             Other   \n",
      "3              1   kevon        dixon    0.0            1  African-American   \n",
      "4              2      ed        philo    0.0            1  African-American   \n",
      "5              3   marcu        brown    1.0            0  African-American   \n",
      "6              4  bouthy  pierrelouis    0.0            0             Other   \n",
      "\n",
      "            sex          age_cat sex_pred  sex_pred_prob race_pred  \\\n",
      "entity_id                                                            \n",
      "1          Male  Greater than 45     male       0.995905        HL   \n",
      "3          Male          25 - 45     male       0.975798      B_NL   \n",
      "4          Male     Less than 25     male       0.980483         A   \n",
      "5          Male     Less than 25     male       0.791925      B_NL   \n",
      "6          Male          25 - 45     male       0.642284      B_NL   \n",
      "\n",
      "           race_pred_prob  \n",
      "entity_id                  \n",
      "1                0.975585  \n",
      "3                0.857721  \n",
      "4                0.610585  \n",
      "5                0.762988  \n",
      "6                0.802566  \n"
     ]
    }
   ],
   "source": [
    "# >>> TODO: Save results to dataframe\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.set_index('entity_id', inplace=True)\n",
    "\n",
    "# Convert results (list of openapi_client.models.personal_name_gendered_out.PersonalNameGenderedOut) to (list of dictionaries)\n",
    "print('Filling the results into the names dataframe...')\n",
    "for i in range(len(result_gender)):\n",
    "    oapi_el = result_gender[i]\n",
    "    current_id = int(oapi_el.id)\n",
    "    df.loc[current_id, 'sex_pred'] = oapi_el.likely_gender\n",
    "    df.loc[current_id, 'sex_pred_prob'] = oapi_el.probability_calibrated\n",
    "    \n",
    "    oapi_el = result_ethnicity[i]\n",
    "    df.loc[current_id, 'race_pred'] = oapi_el.race_ethnicity\n",
    "    df.loc[current_id, 'race_pred_prob'] = oapi_el.probability_calibrated\n",
    "\n",
    "print('Dataframe completed with API results. Here are some results: {}'.format(df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Map NamSor ethnicity categories to COMPAS race categories or vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'African-American', 'Caucasian', 'Hispanic',\n",
       "       'Native American', 'Asian'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.race.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HL', 'B_NL', 'A', 'W_NL', nan], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.race_pred.unique()\n",
    "# \"Output is W_NL (white, non latino), HL (hispano latino), A (asian, non latino), B_NL (black, non latino).\"\n",
    "# Map: W_NL -> Caucasian\n",
    "# HL -> Hispanic\n",
    "# B_NL -> African-American\n",
    "# A -> Asian\n",
    "# Missing: Native American, Other\n",
    "# When does NamSor return nan?\n",
    "# there's a difference made between race and ethnicity in the census https://de.wikipedia.org/wiki/Race_(United_States_Census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving compas dataframe with predictions for gender and ethnicity to CSV... \n",
      "CSV saved!\n"
     ]
    }
   ],
   "source": [
    "# Saving results to 'names_cat.csv'\n",
    "print(\"Saving compas dataframe with predictions for gender and ethnicity to CSV... \")\n",
    "df.to_csv(\"data/compas_with_predictions.csv\")\n",
    "print(\"CSV saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
