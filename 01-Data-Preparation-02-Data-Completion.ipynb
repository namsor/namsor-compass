{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data Preparation\n",
    "\n",
    "To the pre-prepared COMPAS data we add predictions for name gender and origin made as made by NamSor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Import Libraries\n",
    "\n",
    "print(\"Importing necessary libraries... \")\n",
    "\n",
    "import openapi_client #NamSor, see https://github.com/namsor/namsor-python-sdk2\n",
    "from openapi_client.rest import ApiException\n",
    "\n",
    "from aequitas.group import Group # Aequitas, see https://github.com/dssg/aequitas/blob/master/docs/source/examples/compas_demo.ipynb\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Import COMPAS data set\n",
    "\n",
    "print(\"Importing COMPAS data set... \")\n",
    "\n",
    "df = pd.read_csv(\"data/compas_for_namsor.csv\")\n",
    "\n",
    "print(\"Data set imported. It is has {} entries and looks like this:\".format(df.shape[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Preparing for API use\n",
    "\n",
    "# Get private API Key for NamSor API v2 (contained in txt file)\n",
    "print(\"Getting private key... \")\n",
    "\n",
    "key = ''\n",
    "\n",
    "try:\n",
    "    with open(\"key.txt\", \"r\") as file:\n",
    "        key = file.read()\n",
    "    if(len(key) < 0):\n",
    "        raise FileNotFoundError()\n",
    "except (FileNotFoundError):\n",
    "    print(\"Could not find private key. Please make sure you have an API key that you stored as key.txt in the root folder.\")\n",
    "\n",
    "print(\"Got private key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up NamSor API v2 connection settings...\")\n",
    "\n",
    "# Configure API key authorization: api_key\n",
    "configuration = openapi_client.Configuration()\n",
    "configuration.api_key['X-API-KEY'] = key\n",
    "\n",
    "# create an instance of the personal API class\n",
    "pers_api_instance = openapi_client.PersonalApi(openapi_client.ApiClient(configuration))\n",
    "\n",
    "print(\"Connection set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Classifying names with NamSor API\n",
    "\n",
    "# Formatting a df of names and iso2 country codes, which is always 'us' in the COMPAS data set\n",
    "print('Formatting names dataframe...')\n",
    "\n",
    "names_df = df[[]]\n",
    "\n",
    "# Naming convention: https://github.com/namsor/namsor-python-sdk2/blob/master/docs/FirstLastNameGeoIn.md\n",
    "# but is actually (from error message:) \"lastName\", \"id\", \"firstName\", \"countryIso2\"\n",
    "names_df = names_df.assign(id=df['entity_id'].values)\n",
    "names_df = names_df.assign(firstName = df['first'].values)\n",
    "names_df = names_df.assign(lastName = df['last'].values)\n",
    "names_df = names_df.assign(countryIso2='us') # http://www.vas.com/Tnotes/Country%20Codes.htm\n",
    "\n",
    "print('Names dataframe formatted. It looks like this: ')\n",
    "print(names_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting a list of batches from the names df so names can be fed to the API batch-wise\n",
    "\n",
    "print('Creating list of name-batches...')\n",
    "\n",
    "names_stack = list() # this will be a list of name-batches generated from the df\n",
    "\n",
    "limit = len(names_df.index)\n",
    "start = 0\n",
    "end = -1\n",
    "batch_size = 1000 #1000 is the API limit given by NamSor\n",
    "\n",
    "while(end < limit):\n",
    "    start = end + 1\n",
    "    \n",
    "    try_end = end + batch_size\n",
    "    if(try_end <= limit):\n",
    "        end = try_end\n",
    "    else:\n",
    "        end = limit\n",
    "    \n",
    "    # each list item will fit openapi_client.BatchFirstLastNameGeoIn\n",
    "    names_stack.append(list(names_df[start:end].to_dict('record')))\n",
    "    \n",
    "print('List of batches created.')\n",
    "\n",
    "print('Will need to make {} calls.'.format(len(names_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_stack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test & Update for names separated \n",
    "def predict_batch(list_batch_first_last_name_geo_in):\n",
    "    # each dict in the list needs to be transformed into openapi_client.PersonalNameIn(id=entity_id, first=first_name, last=last_name, country_iso2='us')\n",
    "    batch_first_last_name_geo_in = openapi_client.BatchFirstLastNameGeoIn(personal_names=list_batch_first_last_name_geo_in)\n",
    "    api_response = pers_api_instance.gender_geo_batch(batch_first_last_name_geo_in=batch_first_last_name_geo_in)# call api\n",
    "    print(api_response)\n",
    "    #return api_response.personal_names # return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending in one batch at a time and saving the result answer by answer.\n",
    "\n",
    "result = map(predict_batch, names_stack)\n",
    "\n",
    "print(result)\n",
    "\n",
    "#TODO use result to put in df to put in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while (len(names_stack) >= batch_size):\n",
    "#     try:\n",
    "#         result = result + predict_batch(names_stack[start:end])\n",
    "#         del names_stack[start:end] # delete the names that have already been categorized from the stack\n",
    "#         print(\"Batch of names analyzed. {} names left.\".format(len(names_stack)))\n",
    "        \n",
    "#         # categorize remaining names if they are less than a batch size\n",
    "#         if(len(names_stack) < batch_size and len(names_stack) > 0):\n",
    "#             result = result + predict_batch(names_stack)\n",
    "#             names_stack = [] # empty the stack\n",
    "#             print(\"Batch of names analyzed. {} names left.\".format(len(names_stack)))\n",
    "#     except ApiException as e: # Sometimes with a big batch of batches, the API calling gets interrupted (don't panic!)\n",
    "#         print(\"Exception when calling PersonalApi: gender_full_batch: {}\".(e))\n",
    "        \n",
    "#         if((len(list(names.index.values))-len(result)) == len(names_stack)): #check that no names got lost\n",
    "#             print(\"No names got lost. Trying again with stack size {}...\".format(len(names_stack)))\n",
    "#             continue\n",
    "#         else:\n",
    "#             print(\"Some names got lost when the exception occurred. Please try again.\")\n",
    "\n",
    "# print(\"All batches analyzed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> TODO: Save results to dataframe\n",
    "\n",
    "# Convert results (list of openapi_client.models.personal_name_gendered_out.PersonalNameGenderedOut) to (list of dictionaries)\n",
    "print('Filling the results into the names dataframe...')\n",
    "for oapi_el in result:\n",
    "    # names.at[oapi_el.id, 'likely_gender'] = oapi_el.likely_gender\n",
    "    # names.at[oapi_el.id, 'score'] = oapi_el.score\n",
    "print('Dataframe completed with API results. Here are some results: {}'.format(names[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
