{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data Preparation\n",
    "\n",
    "To the pre-prepared COMPAS data we add predictions for name gender and origin made as made by NamSor API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Import Libraries\n",
    "\n",
    "print(\"Importing necessary libraries... \")\n",
    "\n",
    "import openapi_client #NamSor, see https://github.com/namsor/namsor-python-sdk2\n",
    "from openapi_client.rest import ApiException\n",
    "\n",
    "from aequitas.group import Group # Aequitas, see https://github.com/dssg/aequitas/blob/master/docs/source/examples/compas_demo.ipynb\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Import COMPAS data set\n",
    "\n",
    "print(\"Importing COMPAS data set... \")\n",
    "\n",
    "df = pd.read_csv(\"data/compas_for_namsor.csv\")\n",
    "\n",
    "print(\"Data set imported. It is has {} entries and looks like this:\".format(df.shape[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Preparing for API use\n",
    "\n",
    "# Get private API Key for NamSor API v2 (contained in txt file)\n",
    "print(\"Getting private key... \")\n",
    "\n",
    "key = ''\n",
    "\n",
    "try:\n",
    "    with open(\"key.txt\", \"r\") as file:\n",
    "        key = file.read()\n",
    "    if(len(key) < 0):\n",
    "        raise FileNotFoundError()\n",
    "except (FileNotFoundError):\n",
    "    print(\"Could not find private key. Please make sure you have an API key that you stored as key.txt in the root folder.\")\n",
    "\n",
    "print(\"Got private key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up NamSor API v2 connection settings...\")\n",
    "\n",
    "# Configure API key authorization: api_key\n",
    "configuration = openapi_client.Configuration()\n",
    "configuration.api_key['X-API-KEY'] = key\n",
    "\n",
    "# create an instance of the personal API class\n",
    "pers_api_instance = openapi_client.PersonalApi(openapi_client.ApiClient(configuration))\n",
    "\n",
    "print(\"Connection set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test & Update for names separated \n",
    "def predict_batch(li):\n",
    "    \"This function prepares a list of unformatted names for the API call and then calls the API calling function. It returns the API's name classifications.\"\n",
    "    personal_names = list(map(openapi_client.PersonalNameIn(id=name, name=name), li))  # format the names\n",
    "    batch_personal_name_in = openapi_client.BatchPersonalNameIn(personal_names=personal_names)# format the batch\n",
    "    api_response =  pers_api_instance.gender_full_batch(batch_personal_name_in=batch_personal_name_in)# call api\n",
    "    return api_response.personal_names # return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> Classifying names with NamSor API\n",
    "\n",
    "# Sending in one batch at a time and saving the result answer by answer.\n",
    "\n",
    "batch_size = 1000 #1000 is the API limit given by NamSor\n",
    "start = 0\n",
    "end = batch_size\n",
    "result = []\n",
    "\n",
    "names_stack = list(); # TODO: create list of first and last names\n",
    "\n",
    "print('Will need to make {} calls.'.format(len(names_stack) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (len(names_stack) >= batch_size):\n",
    "    try:\n",
    "        result = result + predict_batch(names_stack[start:end])\n",
    "        del names_stack[start:end] # delete the names that have already been categorized from the stack\n",
    "        print(\"Batch of names analyzed. {} names left.\".format(len(names_stack)))\n",
    "        \n",
    "        # categorize remaining names if they are less than a batch size\n",
    "        if(len(names_stack) < batch_size and len(names_stack) > 0):\n",
    "            result = result + predict_batch(names_stack)\n",
    "            names_stack = [] # empty the stack\n",
    "            print(\"Batch of names analyzed. {} names left.\".format(len(names_stack)))\n",
    "    except ApiException as e: # Sometimes with a big batch of batches, the API calling gets interrupted (don't panic!)\n",
    "        print(\"Exception when calling PersonalApi: gender_full_batch: {}\".(e))\n",
    "        \n",
    "        if((len(list(names.index.values))-len(result)) == len(names_stack)): #check that no names got lost\n",
    "            print(\"No names got lost. Trying again with stack size {}...\".format(len(names_stack)))\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Some names got lost when the exception occurred. Please try again.\")\n",
    "\n",
    "print(\"All batches analyzed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> TODO: Save results to dataframe\n",
    "\n",
    "# Convert results (list of openapi_client.models.personal_name_gendered_out.PersonalNameGenderedOut) to (list of dictionaries)\n",
    "print('Filling the results into the names dataframe...')\n",
    "for oapi_el in result:\n",
    "    # names.at[oapi_el.id, 'likely_gender'] = oapi_el.likely_gender\n",
    "    # names.at[oapi_el.id, 'score'] = oapi_el.score\n",
    "print('Dataframe completed with API results. Here are some results: {}'.format(names[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
